{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None) #setting max colwidth to view the entire dataset when using the print() command\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from IPython.display import display\n",
    "\n",
    "# import the files\n",
    "data = open(\"./dataset/breast-cancer.data\")\n",
    "feat = open(\"./dataset/breast-cancer.names\")\n",
    "\n",
    "data = data.read()\n",
    "feat = feat.read()\n",
    "\n",
    "# replace missing dataset attributes to NAN\n",
    "data = data.replace('?','')\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "# convert data from str to dataframe\n",
    "data = StringIO(data)\n",
    "data = pd.read_csv(data, sep=\",\")\n",
    "\n",
    "data.columns = ['class', 'age', 'menopause', 'tumour_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irrad']\n",
    "\n",
    "\n",
    "\n",
    "X = data.drop(['class'], axis = 1)\n",
    "y = data['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "y_test = y_test.replace(['no-recurrence-events','recurrence-events'], [0,1])\n",
    "y_train = y_train.replace(['no-recurrence-events', 'recurrence-events'], [0,1])\n",
    "\n",
    "\n",
    "X_train.drop(['age','menopause', 'breast'], axis=1)\n",
    "X_test.drop(['age','menopause', 'breast'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "\n",
    "\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "def mix(X_train, X_test, y_train, y_test):\n",
    "    k = 1\n",
    "    while k < 50:\n",
    "        X_trainin = X_train\n",
    "        X_testin = X_test\n",
    "        y_trainin = y_train\n",
    "        y_testin = y_test\n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        X_train = selector.fit_transform(X_trainin, y_trainin)\n",
    "        X_test = selector.transform(X_testin)\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_trainin, y_trainin)\n",
    "        y_pred = clf.predict(X_testin)\n",
    "        r_acc = clf.score(X_trainin, y_trainin)\n",
    "        r_f1 = f1_score(y_testin, y_pred)\n",
    "        print(r_acc)\n",
    "        print(r_f1)\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [228, 57]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mix(X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m, in \u001b[0;36mmix\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mwhile\u001b[39;00m k \u001b[39m<\u001b[39m \u001b[39m50\u001b[39m:\n\u001b[0;32m     29\u001b[0m     selector \u001b[39m=\u001b[39m SelectKBest(chi2, k\u001b[39m=\u001b[39mk)\n\u001b[1;32m---> 30\u001b[0m     X_train \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mfit_transform(X_train, y_train)\n\u001b[0;32m     31\u001b[0m     X_test \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     33\u001b[0m     clf \u001b[39m=\u001b[39m RandomForestClassifier()\n",
      "File \u001b[1;32mc:\\Users\\datac\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:855\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\datac\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:397\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m    381\u001b[0m     \u001b[39m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[0;32m    383\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    398\u001b[0m         X, y, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    399\u001b[0m     )\n\u001b[0;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func):\n\u001b[0;32m    402\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    403\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe score function should be a callable, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) was passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    404\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func))\n\u001b[0;32m    405\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\datac\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\datac\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:981\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m--> 981\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m    983\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\datac\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [228, 57]"
     ]
    }
   ],
   "source": [
    "mix(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd87b69d6fc76c572fede75f7bc461ac068fdc8b40cdeead53c03d51dc6c0c1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
